{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nishant/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from random import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from tqdm import tqdm\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "IMG_SIZE = 32\n",
    "\n",
    "\n",
    "#Path\n",
    "DATA_PATH= \"/home/nishant/Desktop/Dataset/DevanagariHandwrittenCharacterDataset\"\n",
    "num_classes = len(os.listdir(DATA_PATH + \"/Train\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test Directory\n",
    "\n",
    "TEST_DIR=DATA_PATH +\"/Test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCV2(image, IMG_SIZE):\n",
    "    img = cv2.imread(image, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))\n",
    "    return img\n",
    "\n",
    "# Input: Folder Path\n",
    "# Output: Tuple (Label, Indices of the labels, one-hot encoded labels)\n",
    "def get_labels(path=DATA_PATH+\"/Train\"):\n",
    "    labels = os.listdir(path)\n",
    "    label_indices = np.arange(0, len(labels))\n",
    "    return labels, label_indices, to_categorical(label_indices)\n",
    "\n",
    "# Function to save all the images in numpy array\n",
    "def save_data_to_array(IMG_SIZE, path=DATA_PATH+\"/Train\"):\n",
    "    labels, _, _ = get_labels(path)\n",
    "\n",
    "    for label in labels:\n",
    "        cv2_vectors = []\n",
    "        images = [path + \"/\" + label + '/' + image for image in os.listdir(path + '/' + label)]\n",
    "        for image in tqdm(images, \"Saving vectors of label - '{}'\".format(label)):\n",
    "            cv2V = getCV2(image, IMG_SIZE)\n",
    "            cv2_vectors.append(cv2V)\n",
    "        np.save(DATA_PATH +\"/\" + label + '.npy', cv2_vectors)\n",
    "\n",
    "# Function for getting train and validation data\n",
    "\n",
    "def get_train_test(split_ratio=0.7, random_state=42):\n",
    "    # Get available labels\n",
    "    labels, indices, _ = get_labels(DATA_PATH + \"/Train\")\n",
    "\n",
    "    # Getting first arrays\n",
    "    X = np.load(DATA_PATH + \"/\" + labels[0] + '.npy')\n",
    "    y = np.zeros(X.shape[0])\n",
    "\n",
    "    # Append all of the dataset into one single array, same goes for y\n",
    "    for i, label in enumerate(labels[1:]):\n",
    "        x = np.load(DATA_PATH + \"/\" + label + '.npy')\n",
    "        X = np.vstack((X, x))\n",
    "        y = np.append(y, np.full(x.shape[0], fill_value= (i + 1)))\n",
    "\n",
    "    assert X.shape[0] == len(y)\n",
    "\n",
    "    return train_test_split(X, y, test_size= (1 - split_ratio), random_state=random_state, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving vectors of label - 'digit_2': 100%|██████████| 1700/1700 [00:00<00:00, 3814.93it/s]\n",
      "Saving vectors of label - 'character_12_thaa': 100%|██████████| 1700/1700 [00:00<00:00, 5137.60it/s]\n",
      "Saving vectors of label - 'character_17_tha': 100%|██████████| 1700/1700 [00:00<00:00, 3588.15it/s]\n",
      "Saving vectors of label - 'character_11_taamatar': 100%|██████████| 1700/1700 [00:00<00:00, 4767.37it/s]\n",
      "Saving vectors of label - 'character_15_adna': 100%|██████████| 1700/1700 [00:00<00:00, 3817.68it/s]\n",
      "Saving vectors of label - 'character_32_patalosaw': 100%|██████████| 1700/1700 [00:00<00:00, 4528.31it/s]\n",
      "Saving vectors of label - 'digit_6': 100%|██████████| 1700/1700 [00:00<00:00, 4984.62it/s]\n",
      "Saving vectors of label - 'character_3_ga': 100%|██████████| 1700/1700 [00:00<00:00, 5462.51it/s]\n",
      "Saving vectors of label - 'character_2_kha': 100%|██████████| 1700/1700 [00:00<00:00, 4250.76it/s]\n",
      "Saving vectors of label - 'character_25_ma': 100%|██████████| 1700/1700 [00:00<00:00, 4956.04it/s]\n",
      "Saving vectors of label - 'character_36_gya': 100%|██████████| 1700/1700 [00:00<00:00, 4451.91it/s]\n",
      "Saving vectors of label - 'character_27_ra': 100%|██████████| 1700/1700 [00:00<00:00, 5757.38it/s]\n",
      "Saving vectors of label - 'character_16_tabala': 100%|██████████| 1700/1700 [00:00<00:00, 5352.37it/s]\n",
      "Saving vectors of label - 'character_1_ka': 100%|██████████| 1700/1700 [00:00<00:00, 5185.50it/s]\n",
      "Saving vectors of label - 'digit_8': 100%|██████████| 1700/1700 [00:00<00:00, 4517.51it/s]\n",
      "Saving vectors of label - 'character_7_chha': 100%|██████████| 1700/1700 [00:00<00:00, 4875.27it/s]\n",
      "Saving vectors of label - 'character_22_pha': 100%|██████████| 1700/1700 [00:00<00:00, 4606.90it/s]\n",
      "Saving vectors of label - 'digit_1': 100%|██████████| 1700/1700 [00:00<00:00, 5430.81it/s]\n",
      "Saving vectors of label - 'digit_0': 100%|██████████| 1700/1700 [00:00<00:00, 3923.34it/s]\n",
      "Saving vectors of label - 'character_30_motosaw': 100%|██████████| 1700/1700 [00:00<00:00, 3576.44it/s]\n",
      "Saving vectors of label - 'character_13_daa': 100%|██████████| 1700/1700 [00:00<00:00, 4481.36it/s]\n",
      "Saving vectors of label - 'digit_4': 100%|██████████| 1700/1700 [00:00<00:00, 3588.14it/s]\n",
      "Saving vectors of label - 'character_8_ja': 100%|██████████| 1700/1700 [00:00<00:00, 4898.76it/s]\n",
      "Saving vectors of label - 'character_23_ba': 100%|██████████| 1700/1700 [00:00<00:00, 4316.72it/s]\n",
      "Saving vectors of label - 'digit_9': 100%|██████████| 1700/1700 [00:00<00:00, 4772.96it/s]\n",
      "Saving vectors of label - 'character_33_ha': 100%|██████████| 1700/1700 [00:00<00:00, 4674.53it/s]\n",
      "Saving vectors of label - 'character_35_tra': 100%|██████████| 1700/1700 [00:00<00:00, 4276.18it/s]\n",
      "Saving vectors of label - 'character_9_jha': 100%|██████████| 1700/1700 [00:00<00:00, 4508.58it/s]\n",
      "Saving vectors of label - 'character_20_na': 100%|██████████| 1700/1700 [00:00<00:00, 5255.32it/s]\n",
      "Saving vectors of label - 'digit_5': 100%|██████████| 1700/1700 [00:00<00:00, 4493.10it/s]\n",
      "Saving vectors of label - 'character_34_chhya': 100%|██████████| 1700/1700 [00:00<00:00, 5457.52it/s]\n",
      "Saving vectors of label - 'digit_3': 100%|██████████| 1700/1700 [00:00<00:00, 4661.56it/s]\n",
      "Saving vectors of label - 'character_14_dhaa': 100%|██████████| 1700/1700 [00:00<00:00, 4559.86it/s]\n",
      "Saving vectors of label - 'character_19_dha': 100%|██████████| 1700/1700 [00:00<00:00, 4411.86it/s]\n",
      "Saving vectors of label - 'character_31_petchiryakha': 100%|██████████| 1700/1700 [00:00<00:00, 4692.14it/s]\n",
      "Saving vectors of label - 'character_18_da': 100%|██████████| 1700/1700 [00:00<00:00, 4647.16it/s]\n",
      "Saving vectors of label - 'character_6_cha': 100%|██████████| 1700/1700 [00:00<00:00, 4926.00it/s]\n",
      "Saving vectors of label - 'character_4_gha': 100%|██████████| 1700/1700 [00:00<00:00, 4270.11it/s]\n",
      "Saving vectors of label - 'character_26_yaw': 100%|██████████| 1700/1700 [00:00<00:00, 4011.82it/s]\n",
      "Saving vectors of label - 'character_10_yna': 100%|██████████| 1700/1700 [00:00<00:00, 5487.78it/s]\n",
      "Saving vectors of label - 'character_29_waw': 100%|██████████| 1700/1700 [00:00<00:00, 4740.03it/s]\n",
      "Saving vectors of label - 'character_5_kna': 100%|██████████| 1700/1700 [00:00<00:00, 4318.77it/s]\n",
      "Saving vectors of label - 'digit_7': 100%|██████████| 1700/1700 [00:00<00:00, 4822.64it/s]\n",
      "Saving vectors of label - 'character_28_la': 100%|██████████| 1700/1700 [00:00<00:00, 4548.47it/s]\n",
      "Saving vectors of label - 'character_24_bha': 100%|██████████| 1700/1700 [00:00<00:00, 4710.40it/s]\n",
      "Saving vectors of label - 'character_21_pa': 100%|██████████| 1700/1700 [00:00<00:00, 4694.96it/s]\n"
     ]
    }
   ],
   "source": [
    "# save all the images in numpy array\n",
    "\n",
    "save_data_to_array(IMG_SIZE,DATA_PATH + \"/Train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Loading train set and test set\n",
    "X_train, X_test, y_train, y_test = get_train_test()\n",
    "\n",
    "#X = X_train.reshape(X_train.shape[0], IMG_SIZE, IMG_SIZE, 1)\n",
    "#validate_x = X_test.reshape(X_test.shape[0], IMG_SIZE, IMG_SIZE, 1)\n",
    "\n",
    "\n",
    "#Y = to_categorical(y_train)\n",
    "#validate_y = to_categorical(y_test)\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_validate = le.transform(y_test)\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_validate = to_categorical(y_test, num_classes)\n",
    "\n",
    "im_shape = (IMG_SIZE, IMG_SIZE, 1)\n",
    "X_train = X_train.reshape(X_train.shape[0], *im_shape)\n",
    "X_test = X_test.reshape(X_test.shape[0], *im_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Activation, MaxPool2D\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import SimpleRNN\n",
    "from keras import initializers\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.models import load_model\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# My cnn model\n",
    "\n",
    "cnn = Sequential()\n",
    "kernelSize = (3, 3)\n",
    "ip_activation = 'relu'\n",
    "cnn.add(Conv2D(filters=32, kernel_size=kernelSize, input_shape=im_shape, activation='relu'))\n",
    "cnn.add(Conv2D(filters=64, kernel_size=kernelSize, activation=ip_activation))\n",
    "cnn.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding=\"same\"))\n",
    "cnn.add(Conv2D(filters=64, kernel_size=kernelSize, activation=ip_activation))\n",
    "cnn.add(Conv2D(filters=64, kernel_size=kernelSize, activation=ip_activation))\n",
    "cnn.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding=\"same\"))\n",
    "cnn.add(Dropout(0.2))\n",
    "cnn.add(Flatten())\n",
    "cnn.add(Dense(units=128, activation=ip_activation, kernel_initializer='uniform'))\n",
    "cnn.add(Dense(units=64, activation=ip_activation, kernel_initializer='uniform'))\n",
    "op_activation = 'softmax'\n",
    "cnn.add(Dense(units=num_classes, activation=op_activation, kernel_initializer='uniform'))\n",
    "optimize = 'adam'\n",
    "loss = 'categorical_crossentropy'\n",
    "metrics = ['accuracy']\n",
    "cnn.compile(optimizer=optimize, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54739 samples, validate on 23461 samples\n",
      "Epoch 1/20\n",
      "54739/54739 [==============================] - 86s 2ms/step - loss: 0.0440 - acc: 0.9880 - val_loss: 0.1020 - val_acc: 0.9809\n",
      "Epoch 2/20\n",
      "54739/54739 [==============================] - 90s 2ms/step - loss: 0.0458 - acc: 0.9882 - val_loss: 0.1069 - val_acc: 0.9800\n",
      "Epoch 3/20\n",
      "54739/54739 [==============================] - 93s 2ms/step - loss: 0.0439 - acc: 0.9886 - val_loss: 0.1095 - val_acc: 0.9802\n",
      "Epoch 4/20\n",
      "54739/54739 [==============================] - 94s 2ms/step - loss: 0.0438 - acc: 0.9883 - val_loss: 0.1113 - val_acc: 0.9785\n",
      "Epoch 5/20\n",
      "54739/54739 [==============================] - 94s 2ms/step - loss: 0.0426 - acc: 0.9891 - val_loss: 0.1472 - val_acc: 0.9686\n",
      "Epoch 6/20\n",
      "54739/54739 [==============================] - 96s 2ms/step - loss: 0.0519 - acc: 0.9880 - val_loss: 0.1252 - val_acc: 0.9762\n",
      "Epoch 7/20\n",
      "54739/54739 [==============================] - 96s 2ms/step - loss: 0.0434 - acc: 0.9892 - val_loss: 0.1000 - val_acc: 0.9812\n",
      "Epoch 8/20\n",
      "54739/54739 [==============================] - 96s 2ms/step - loss: 0.0501 - acc: 0.9883 - val_loss: 0.1593 - val_acc: 0.9739\n",
      "Epoch 9/20\n",
      "54739/54739 [==============================] - 98s 2ms/step - loss: 0.0487 - acc: 0.9889 - val_loss: 0.1166 - val_acc: 0.9798\n",
      "Epoch 10/20\n",
      "54739/54739 [==============================] - 97s 2ms/step - loss: 0.0514 - acc: 0.9884 - val_loss: 0.1327 - val_acc: 0.9802\n",
      "Epoch 11/20\n",
      "54739/54739 [==============================] - 97s 2ms/step - loss: 0.0407 - acc: 0.9903 - val_loss: 0.1263 - val_acc: 0.9799\n",
      "Epoch 12/20\n",
      "54739/54739 [==============================] - 98s 2ms/step - loss: 0.0613 - acc: 0.9877 - val_loss: 0.1253 - val_acc: 0.9789\n",
      "Epoch 13/20\n",
      "54739/54739 [==============================] - 98s 2ms/step - loss: 0.0366 - acc: 0.9912 - val_loss: 0.2442 - val_acc: 0.9533\n",
      "Epoch 14/20\n",
      "54739/54739 [==============================] - 99s 2ms/step - loss: 0.0524 - acc: 0.9881 - val_loss: 0.1540 - val_acc: 0.9777\n",
      "Epoch 15/20\n",
      "54739/54739 [==============================] - 97s 2ms/step - loss: 0.0507 - acc: 0.9886 - val_loss: 0.1420 - val_acc: 0.9783\n",
      "Epoch 16/20\n",
      "54739/54739 [==============================] - 99s 2ms/step - loss: 0.0567 - acc: 0.9889 - val_loss: 0.1671 - val_acc: 0.9769\n",
      "Epoch 17/20\n",
      "54739/54739 [==============================] - 99s 2ms/step - loss: 0.0512 - acc: 0.9898 - val_loss: 0.1710 - val_acc: 0.9775\n",
      "Epoch 18/20\n",
      "54739/54739 [==============================] - 100s 2ms/step - loss: 0.0642 - acc: 0.9883 - val_loss: 0.1645 - val_acc: 0.9772\n",
      "Epoch 19/20\n",
      "54739/54739 [==============================] - 99s 2ms/step - loss: 0.0590 - acc: 0.9880 - val_loss: 0.1560 - val_acc: 0.9776\n",
      "Epoch 20/20\n",
      "54739/54739 [==============================] - 99s 2ms/step - loss: 0.0514 - acc: 0.9899 - val_loss: 0.1257 - val_acc: 0.9802\n"
     ]
    }
   ],
   "source": [
    "# In the 20 epochs, the training accuracy is 98.99% and validation accuracy is 98.02 on the training dataset\n",
    "\n",
    "history = cnn.fit(X_train, y_train,\n",
    "                  batch_size=32, epochs=20,\n",
    "                  validation_data=(X_test, y_validate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predit label of the image using model\n",
    "\n",
    "def predict(filename, model):\n",
    "    path = os.path.join(TEST_DIR, filename)\n",
    "    img = cv2.imread(path,cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))\n",
    "    img = np.array(img)\n",
    "    data = img.reshape(-1, IMG_SIZE,IMG_SIZE,1)\n",
    "    res = get_labels()[0][np.argmax(model.predict(data))]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.981231884057971\n"
     ]
    }
   ],
   "source": [
    "# Finding Testing Accuracy on the Test data which is given in the Dataset\n",
    "\n",
    "ctr_true = 0\n",
    "ctr_total = 0\n",
    "labels = os.listdir(TEST_DIR)\n",
    "# labels\n",
    "for label in labels:\n",
    "    images = os.listdir(TEST_DIR + \"/\" + label)\n",
    "#     print(images)\n",
    "    for img in images:\n",
    "        out = predict(label + \"/\" + img, cnn)\n",
    "        if out == label:\n",
    "            ctr_true += 1\n",
    "        ctr_total += 1\n",
    "    \n",
    "print(ctr_true/ctr_total)\n",
    "\n",
    "# Testing Accuracy: 98.12%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
